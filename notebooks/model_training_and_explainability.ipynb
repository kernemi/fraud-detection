{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6e67110",
   "metadata": {},
   "source": [
    "# Model Training and Explainability Analysis\n",
    "## Tasks 2 Model Building, Training, and SHAP Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b2a3205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom utilities\n",
    "from components.dataUtilities import DataLoader, DataCleaner, merge_with_geolocation\n",
    "from components.featureEngineering import FeatureEngineer, create_all_features\n",
    "from components.preprocessing import full_preprocessing_pipeline\n",
    "from components.model_training import ModelTrainer, cross_validate_models\n",
    "from components.model_evaluation import evaluate_models_comprehensive\n",
    "from components.model_explainability import explain_best_model\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee084f87",
   "metadata": {},
   "source": [
    "1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f24599f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA PREPARATION ===\n",
      "Fraud data loaded: (151112, 11)\n",
      "Credit card data loaded: (284807, 31)\n",
      "Missing values before cleaning:\n",
      "user_id           0\n",
      "signup_time       0\n",
      "purchase_time     0\n",
      "purchase_value    0\n",
      "device_id         0\n",
      "source            0\n",
      "browser           0\n",
      "sex               0\n",
      "age               0\n",
      "ip_address        0\n",
      "class             0\n",
      "dtype: int64\n",
      "Missing values after cleaning:\n",
      "user_id           0\n",
      "signup_time       0\n",
      "purchase_time     0\n",
      "purchase_value    0\n",
      "device_id         0\n",
      "source            0\n",
      "browser           0\n",
      "sex               0\n",
      "age               0\n",
      "ip_address        0\n",
      "class             0\n",
      "dtype: int64\n",
      "Duplicates removed: 0 rows\n",
      "Shape before: (151112, 11), Shape after: (151112, 11)\n",
      "Starting comprehensive feature engineering...\n",
      "Time features created: hour_of_day, day_of_week, time_period, is_weekend\n",
      "Time since signup calculated (in hours)\n",
      "Transaction features created for users, devices, and IP addresses\n",
      "Purchase value features created\n",
      "Categorical features encoded: ['source', 'browser', 'sex', 'time_period', 'signup_category', 'purchase_category']\n",
      "Feature engineering complete. Final shape: (151112, 56)\n",
      "Fraud dataset prepared: (151112, 56)\n",
      "Credit card dataset available: (284807, 31)\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data (using preprocessed data from previous analysis)\n",
    "print(\"=== DATA PREPARATION ===\")\n",
    "\n",
    "# Load data\n",
    "data_loader = DataLoader(data_path='../data/raw/')\n",
    "fraud_df = data_loader.load_fraud_data()\n",
    "creditcard_df = data_loader.load_creditcard_data()\n",
    "\n",
    "# Clean and engineer features for fraud data\n",
    "if not fraud_df.empty:\n",
    "    cleaner = DataCleaner()\n",
    "    fraud_df_clean = cleaner.handle_missing_values(fraud_df, strategy='drop')\n",
    "    fraud_df_clean = cleaner.remove_duplicates(fraud_df_clean)\n",
    "    fraud_df_clean = cleaner.correct_data_types(fraud_df_clean)\n",
    "    \n",
    "    # Feature engineering\n",
    "    fraud_df_features = create_all_features(fraud_df_clean)\n",
    "    \n",
    "    print(f\"Fraud dataset prepared: {fraud_df_features.shape}\")\n",
    "else:\n",
    "    print(\"Fraud dataset not available\")\n",
    "\n",
    "# Prepare creditcard data if available\n",
    "if not creditcard_df.empty:\n",
    "    print(f\"Credit card dataset available: {creditcard_df.shape}\")\n",
    "else:\n",
    "    print(\"Credit card dataset not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08386b98",
   "metadata": {},
   "source": [
    "2. Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8da2644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREPROCESSING FRAUD DATA ===\n",
      "Starting preprocessing pipeline...\n",
      "Preparing features...\n",
      "Removing datetime columns: ['signup_time', 'purchase_time', 'user_first_transaction', 'user_last_transaction']\n",
      "Removing datetime columns: ['signup_time', 'purchase_time', 'user_first_transaction', 'user_last_transaction']\n",
      "Dropping all-NaN columns: ['user_transaction_std']\n",
      "Dropping all-NaN columns: ['user_transaction_std']\n",
      "Applying SMOTE...\n",
      "✅ Preprocessing completed successfully!\n",
      "Fraud data preprocessing completed!\n",
      "Training set: (219136, 47)\n",
      "Test set: (30223, 47)\n",
      "Features: 47\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing pipeline for fraud data\n",
    "if not fraud_df_features.empty:\n",
    "    print(\"=== PREPROCESSING FRAUD DATA ===\")\n",
    "    \n",
    "    # Full preprocessing pipeline\n",
    "    fraud_processed = full_preprocessing_pipeline(\n",
    "        fraud_df_features,\n",
    "        target_col='class',\n",
    "        sampling_strategy='smote',\n",
    "        scaling_method='standard'\n",
    "    )\n",
    "    \n",
    "    print(\"Fraud data preprocessing completed!\")\n",
    "    print(f\"Training set: {fraud_processed['X_train'].shape}\")\n",
    "    print(f\"Test set: {fraud_processed['X_test'].shape}\")\n",
    "    print(f\"Features: {len(fraud_processed['feature_names'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "640f7044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING MODELS ON FRAUD DATA ===\n",
      "Training 3 models...\n",
      "============================================================\n",
      "\n",
      "LOGISTIC REGRESSION\n",
      "----------------------------------------\n",
      "Training Logistic Regression model...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m trainer = ModelTrainer(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Train models\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m fraud_models = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_all_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfraud_processed\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mX_train\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfraud_processed\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43my_train\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodels_to_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlogistic_regression\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrandom_forest\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mxgboost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mModel training completed for fraud data!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModels trained: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(fraud_models.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\notebooks\\..\\components\\model_training.py:309\u001b[39m, in \u001b[36mModelTrainer.train_all_models\u001b[39m\u001b[34m(self, X_train, y_train, models_to_train, hyperparameter_tuning)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m40\u001b[39m)\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_name == \u001b[33m'\u001b[39m\u001b[33mlogistic_regression\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_logistic_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m model_name == \u001b[33m'\u001b[39m\u001b[33mrandom_forest\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    311\u001b[39m     model = \u001b[38;5;28mself\u001b[39m.train_random_forest(X_train, y_train, hyperparameter_tuning)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\notebooks\\..\\components\\model_training.py:64\u001b[39m, in \u001b[36mModelTrainer.train_logistic_regression\u001b[39m\u001b[34m(self, X_train, y_train, hyperparameter_tuning)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Perform grid search with cross-validation\u001b[39;00m\n\u001b[32m     55\u001b[39m grid_search = GridSearchCV(\n\u001b[32m     56\u001b[39m     base_model, \n\u001b[32m     57\u001b[39m     param_grid, \n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     62\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Store best parameters\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mself\u001b[39m.best_params[\u001b[33m'\u001b[39m\u001b[33mlogistic_regression\u001b[39m\u001b[33m'\u001b[39m] = grid_search.best_params_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\venv\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1467\u001b[39m     estimator._validate_params()\n\u001b[32m   1469\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1470\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1471\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1472\u001b[39m     )\n\u001b[32m   1473\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1474\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    964\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m    965\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m    966\u001b[39m     )\n\u001b[32m    968\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m    973\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m    974\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1525\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1526\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    908\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    909\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    910\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    911\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    912\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    913\u001b[39m         )\n\u001b[32m    914\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    935\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    936\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    937\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    938\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    939\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     62\u001b[39m config = get_config()\n\u001b[32m     63\u001b[39m iterable_with_config = (\n\u001b[32m     64\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     66\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train models on fraud data\n",
    "if 'fraud_processed' in locals():\n",
    "    print(\"=== TRAINING MODELS ON FRAUD DATA ===\")\n",
    "    \n",
    "    # Initialize model trainer\n",
    "    trainer = ModelTrainer(random_state=42)\n",
    "    \n",
    "    # Train models\n",
    "    fraud_models = trainer.train_all_models(\n",
    "        fraud_processed['X_train'],\n",
    "        fraud_processed['y_train'],\n",
    "        models_to_train=['logistic_regression', 'random_forest', 'xgboost'],\n",
    "        hyperparameter_tuning=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nModel training completed for fraud data!\")\n",
    "    print(f\"Models trained: {list(fraud_models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98098e8e",
   "metadata": {},
   "source": [
    "3. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb9d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive model evaluation for fraud data\n",
    "if 'fraud_models' in locals():\n",
    "    print(\"=== COMPREHENSIVE MODEL EVALUATION ===\")\n",
    "    \n",
    "    # Evaluate all models\n",
    "    fraud_comparison, fraud_best_model = evaluate_models_comprehensive(\n",
    "        fraud_models,\n",
    "        fraud_processed['X_train'],\n",
    "        fraud_processed['y_train'],\n",
    "        fraud_processed['X_test'],\n",
    "        fraud_processed['y_test'],\n",
    "        fraud_processed['feature_names']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nBest model for fraud detection: {fraud_best_model}\")\n",
    "    \n",
    "    # Display comparison results\n",
    "    print(\"\\nModel Comparison Results:\")\n",
    "    display(fraud_comparison[['f1_score', 'precision', 'recall', 'pr_auc', 'roc_auc']].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67ecd5",
   "metadata": {},
   "source": [
    "4. Model Selection Justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "498417e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed justification for best model selection\n",
    "if 'fraud_comparison' in locals():\n",
    "    print(\"=== MODEL SELECTION JUSTIFICATION ===\")\n",
    "    print(\"\\nFor fraud detection, we prioritize:\")\n",
    "    print(\"1. F1-Score: Balance between precision and recall\")\n",
    "    print(\"2. PR-AUC: Performance on imbalanced data\")\n",
    "    print(\"3. Recall: Catching actual fraud cases\")\n",
    "    print(\"4. Precision: Minimizing false positives\")\n",
    "    \n",
    "    # Rank models by key metrics\n",
    "    key_metrics = ['f1_score', 'pr_auc', 'recall', 'precision']\n",
    "    \n",
    "    print(\"\\nModel Rankings by Key Metrics:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for metric in key_metrics:\n",
    "        ranked = fraud_comparison.sort_values(metric, ascending=False)\n",
    "        print(f\"\\n{metric.upper()}:\")\n",
    "        for i, (model, score) in enumerate(ranked[metric].items(), 1):\n",
    "            print(f\"  {i}. {model:15}: {score:.4f}\")\n",
    "    \n",
    "    # Business impact analysis\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BUSINESS IMPACT ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    best_model_metrics = fraud_comparison.loc[fraud_best_model]\n",
    "    \n",
    "    print(f\"\\nSelected Model: {fraud_best_model.upper()}\")\n",
    "    print(f\"F1-Score: {best_model_metrics['f1_score']:.4f}\")\n",
    "    print(f\"Precision: {best_model_metrics['precision']:.4f} (False Positive Rate: {1-best_model_metrics['precision']:.4f})\")\n",
    "    print(f\"Recall: {best_model_metrics['recall']:.4f} (False Negative Rate: {1-best_model_metrics['recall']:.4f})\")\n",
    "    print(f\"PR-AUC: {best_model_metrics['pr_auc']:.4f}\")\n",
    "    \n",
    "    print(\"\\nBusiness Justification:\")\n",
    "    print(f\"• Balanced performance with F1-Score of {best_model_metrics['f1_score']:.4f}\")\n",
    "    print(f\"• {best_model_metrics['recall']*100:.1f}% of fraud cases detected\")\n",
    "    print(f\"• {(1-best_model_metrics['precision'])*100:.1f}% false positive rate (acceptable for fraud detection)\")\n",
    "    print(f\"• Strong performance on imbalanced data (PR-AUC: {best_model_metrics['pr_auc']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d74e992",
   "metadata": {},
   "source": [
    "5. SHAP Explainability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf0992b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP explainability for best model\n",
    "if 'fraud_best_model' in locals():\n",
    "    print(\"=== SHAP EXPLAINABILITY ANALYSIS ===\")\n",
    "    \n",
    "    # Get best model\n",
    "    best_model = fraud_models[fraud_best_model]\n",
    "    \n",
    "    # Select sample indices for detailed explanation\n",
    "    fraud_indices = fraud_processed['y_test'][fraud_processed['y_test'] == 1].index[:3].tolist()\n",
    "    legit_indices = fraud_processed['y_test'][fraud_processed['y_test'] == 0].index[:3].tolist()\n",
    "    sample_indices = fraud_indices + legit_indices\n",
    "    \n",
    "    print(f\"Analyzing {len(sample_indices)} sample predictions...\")\n",
    "    \n",
    "    # Comprehensive SHAP analysis\n",
    "    fraud_insights = explain_best_model(\n",
    "        best_model,\n",
    "        fraud_best_model,\n",
    "        fraud_processed['X_train'],\n",
    "        fraud_processed['X_test'],\n",
    "        fraud_processed['y_test'],\n",
    "        sample_indices\n",
    "    )\n",
    "    \n",
    "    print(\"\\nSHAP analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2d6451",
   "metadata": {},
   "source": [
    "6. Credit Card Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "febc8eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREDIT CARD DATA ANALYSIS ===\n",
      "Starting preprocessing pipeline...\n",
      "Preparing features...\n",
      "Applying SMOTE...\n",
      "✅ Preprocessing completed successfully!\n",
      "Training 3 models...\n",
      "============================================================\n",
      "\n",
      "LOGISTIC REGRESSION\n",
      "----------------------------------------\n",
      "Training Logistic Regression model...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Train models\u001b[39;00m\n\u001b[32m     14\u001b[39m cc_trainer = ModelTrainer(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m cc_models = \u001b[43mcc_trainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_all_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreditcard_processed\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mX_train\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreditcard_processed\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43my_train\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodels_to_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlogistic_regression\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrandom_forest\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mxgboost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Evaluate models\u001b[39;00m\n\u001b[32m     23\u001b[39m cc_comparison, cc_best_model = evaluate_models_comprehensive(\n\u001b[32m     24\u001b[39m     cc_models,\n\u001b[32m     25\u001b[39m     creditcard_processed[\u001b[33m'\u001b[39m\u001b[33mX_train\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m     creditcard_processed[\u001b[33m'\u001b[39m\u001b[33mfeature_names\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     30\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\notebooks\\..\\components\\model_training.py:309\u001b[39m, in \u001b[36mModelTrainer.train_all_models\u001b[39m\u001b[34m(self, X_train, y_train, models_to_train, hyperparameter_tuning)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m40\u001b[39m)\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_name == \u001b[33m'\u001b[39m\u001b[33mlogistic_regression\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_logistic_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m model_name == \u001b[33m'\u001b[39m\u001b[33mrandom_forest\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    311\u001b[39m     model = \u001b[38;5;28mself\u001b[39m.train_random_forest(X_train, y_train, hyperparameter_tuning)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\notebooks\\..\\components\\model_training.py:64\u001b[39m, in \u001b[36mModelTrainer.train_logistic_regression\u001b[39m\u001b[34m(self, X_train, y_train, hyperparameter_tuning)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Perform grid search with cross-validation\u001b[39;00m\n\u001b[32m     55\u001b[39m grid_search = GridSearchCV(\n\u001b[32m     56\u001b[39m     base_model, \n\u001b[32m     57\u001b[39m     param_grid, \n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     62\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Store best parameters\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mself\u001b[39m.best_params[\u001b[33m'\u001b[39m\u001b[33mlogistic_regression\u001b[39m\u001b[33m'\u001b[39m] = grid_search.best_params_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\venv\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1467\u001b[39m     estimator._validate_params()\n\u001b[32m   1469\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1470\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1471\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1472\u001b[39m     )\n\u001b[32m   1473\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1474\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    964\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m    965\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m    966\u001b[39m     )\n\u001b[32m    968\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m    973\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m    974\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1525\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1526\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    908\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    909\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    910\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    911\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    912\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    913\u001b[39m         )\n\u001b[32m    914\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    935\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    936\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    937\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    938\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    939\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     62\u001b[39m config = get_config()\n\u001b[32m     63\u001b[39m iterable_with_config = (\n\u001b[32m     64\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     66\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\OneDrive\\Desktop\\My\\mywork\\tenx\\week5\\fraud-detection\\venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Process credit card data if available\n",
    "if not creditcard_df.empty:\n",
    "    print(\"=== CREDIT CARD DATA ANALYSIS ===\")\n",
    "    \n",
    "    # Preprocessing for credit card data\n",
    "    creditcard_processed = full_preprocessing_pipeline(\n",
    "        creditcard_df,\n",
    "        target_col='Class',  # Note: Capital 'C' for creditcard data\n",
    "        sampling_strategy='smote',\n",
    "        scaling_method='standard'\n",
    "    )\n",
    "    \n",
    "    # Train models\n",
    "    cc_trainer = ModelTrainer(random_state=42)\n",
    "    cc_models = cc_trainer.train_all_models(\n",
    "        creditcard_processed['X_train'],\n",
    "        creditcard_processed['y_train'],\n",
    "        models_to_train=['logistic_regression', 'random_forest', 'xgboost'],\n",
    "        hyperparameter_tuning=True\n",
    "    )\n",
    "    \n",
    "    # Evaluate models\n",
    "    cc_comparison, cc_best_model = evaluate_models_comprehensive(\n",
    "        cc_models,\n",
    "        creditcard_processed['X_train'],\n",
    "        creditcard_processed['y_train'],\n",
    "        creditcard_processed['X_test'],\n",
    "        creditcard_processed['y_test'],\n",
    "        creditcard_processed['feature_names']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nBest model for credit card fraud: {cc_best_model}\")\n",
    "    display(cc_comparison[['f1_score', 'precision', 'recall', 'pr_auc', 'roc_auc']].round(4))\n",
    "    \n",
    "else:\n",
    "    print(\"Credit card dataset not available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8041bd",
   "metadata": {},
   "source": [
    "7. Key Findings and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10547a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KEY FINDINGS AND INSIGHTS ===\n",
      "\n",
      "1. MODEL PERFORMANCE SUMMARY\n",
      "----------------------------------------\n",
      "\n",
      "2. FRAUD DRIVER INSIGHTS (from SHAP analysis)\n",
      "--------------------------------------------------\n",
      "\n",
      "3. BUSINESS RECOMMENDATIONS\n",
      "------------------------------\n",
      "• Implement real-time scoring using the best performing model\n",
      "• Focus monitoring on high-risk features identified by SHAP\n",
      "• Set appropriate thresholds balancing fraud detection vs customer experience\n",
      "• Regular model retraining to adapt to new fraud patterns\n",
      "• Use SHAP explanations for fraud investigation and rule creation\n"
     ]
    }
   ],
   "source": [
    "# Summary of key findings\n",
    "print(\"=== KEY FINDINGS AND INSIGHTS ===\")\n",
    "print(\"\\n1. MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if 'fraud_comparison' in locals():\n",
    "    print(f\"\\nFraud Detection Dataset:\")\n",
    "    print(f\"• Best Model: {fraud_best_model}\")\n",
    "    print(f\"• F1-Score: {fraud_comparison.loc[fraud_best_model, 'f1_score']:.4f}\")\n",
    "    print(f\"• PR-AUC: {fraud_comparison.loc[fraud_best_model, 'pr_auc']:.4f}\")\n",
    "    print(f\"• Recall: {fraud_comparison.loc[fraud_best_model, 'recall']:.4f}\")\n",
    "\n",
    "if 'cc_comparison' in locals():\n",
    "    print(f\"\\nCredit Card Dataset:\")\n",
    "    print(f\"• Best Model: {cc_best_model}\")\n",
    "    print(f\"• F1-Score: {cc_comparison.loc[cc_best_model, 'f1_score']:.4f}\")\n",
    "    print(f\"• PR-AUC: {cc_comparison.loc[cc_best_model, 'pr_auc']:.4f}\")\n",
    "    print(f\"• Recall: {cc_comparison.loc[cc_best_model, 'recall']:.4f}\")\n",
    "\n",
    "print(\"\\n2. FRAUD DRIVER INSIGHTS (from SHAP analysis)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if 'fraud_insights' in locals() and fraud_insights:\n",
    "    if 'top_fraud_drivers' in fraud_insights:\n",
    "        print(\"\\nTop Risk Factors:\")\n",
    "        for driver in fraud_insights['top_fraud_drivers'][:5]:\n",
    "            print(f\"• {driver['feature']}: {driver['interpretation']}\")\n",
    "    \n",
    "    if 'protective_factors' in fraud_insights:\n",
    "        print(\"\\nProtective Factors:\")\n",
    "        for factor in fraud_insights['protective_factors'][:5]:\n",
    "            print(f\"• {factor['feature']}: {factor['interpretation']}\")\n",
    "\n",
    "print(\"\\n3. BUSINESS RECOMMENDATIONS\")\n",
    "print(\"-\" * 30)\n",
    "print(\"• Implement real-time scoring using the best performing model\")\n",
    "print(\"• Focus monitoring on high-risk features identified by SHAP\")\n",
    "print(\"• Set appropriate thresholds balancing fraud detection vs customer experience\")\n",
    "print(\"• Regular model retraining to adapt to new fraud patterns\")\n",
    "print(\"• Use SHAP explanations for fraud investigation and rule creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d985c6f",
   "metadata": {},
   "source": [
    "8. Model Deployment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd522b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Models and preprocessing objects saved for deployment!\n"
     ]
    }
   ],
   "source": [
    "# Save best models and preprocessing objects for deployment\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "if 'fraud_best_model' in locals():\n",
    "    # Save fraud detection model and preprocessing objects\n",
    "    joblib.dump(fraud_models[fraud_best_model], f'../models/fraud_best_model_{fraud_best_model}.pkl')\n",
    "    joblib.dump(fraud_processed['scaler'], '../models/fraud_scaler.pkl')\n",
    "    \n",
    "    # Save feature names\n",
    "    with open('../models/fraud_feature_names.txt', 'w') as f:\n",
    "        for feature in fraud_processed['feature_names']:\n",
    "            f.write(f\"{feature}\\n\")\n",
    "    \n",
    "    print(f\"Fraud detection model saved: {fraud_best_model}\")\n",
    "\n",
    "if 'cc_best_model' in locals():\n",
    "    # Save credit card model and preprocessing objects\n",
    "    joblib.dump(cc_models[cc_best_model], f'../models/creditcard_best_model_{cc_best_model}.pkl')\n",
    "    joblib.dump(creditcard_processed['scaler'], '../models/creditcard_scaler.pkl')\n",
    "    \n",
    "    # Save feature names\n",
    "    with open('../models/creditcard_feature_names.txt', 'w') as f:\n",
    "        for feature in creditcard_processed['feature_names']:\n",
    "            f.write(f\"{feature}\\n\")\n",
    "    \n",
    "    print(f\"Credit card model saved: {cc_best_model}\")\n",
    "\n",
    "print(\"\\nModels and preprocessing objects saved for deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
